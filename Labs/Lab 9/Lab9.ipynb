{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqGJpQTYpDaM"
   },
   "source": [
    "# Lab 9: Dissecting racial bias in a medical risk score\n",
    "\n",
    "---\n",
    "\n",
    "ML Failures lab: Dissecting Racial Bias in a Medical Risk Score by Nick Merrill, Inderpal Kaur, Samuel Greenberg is licensed under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0). Edits by Emily Aiken.\n",
    "\n",
    "**Students** can [provide feedback here](https://docs.google.com/forms/d/1jI8oXRkqD1l1ARuZR1y9W_qkOystPr-YEyywNDez46M/edit?ts=5efa772a&dods).\n",
    "\n",
    "# Background\n",
    "\n",
    "To effectively manage patients, health systems often need to estimate particular\n",
    "patients' health risks. Using quantitative measures, or \"risk scores,\"\n",
    "healthcare providers can prioritize patients and allocate resources to patients\n",
    "who need them most.\n",
    "\n",
    "In this lab, we examine an algorithm widely-used in industry to establish quantitative risk scores for patients. This algorithm uses *medical cost* (i.e., the amount a patient spends on medical care) as a proxy for risk. Through analysis of this data, we will discover how this algorithm embeds a bias against Black patients, undervaluing their medical risk relative to White patients. Crucially, this bias is not immediately visible when comparing medical costs across White and Black pateints.\n",
    "\n",
    "The key insight of [Obermeyer et al's work](https://science.sciencemag.org/content/366/6464/447) is that bias frequently slips into algorithmic systems unnoticed, particularly when sensitive characteristics (such as race) are ommitted or backgrounded in the data science process. In this case, bias in algorithms affects people's lives very concretely: the bias in the algorithm described here would make it more difficult for Black patients to recieve the care they need.\n",
    "\n",
    "In this lab, we will learn how to uncover bias in algorithms, using the medical risk score example from Obermeyer et al's paper.\n",
    "\n",
    "## Agenda\n",
    "\n",
    "- Investigate relationship between medical cost and risk by race\n",
    "- Investigate relationship between chronic illness and risk by race\n",
    "- Investigate interactions between medical cost and chronic illness\n",
    "- Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B4AtgFvfIpjv"
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wY-sa4O5IqCJ"
   },
   "source": [
    "## Medical cost and risk\n",
    "\n",
    "To help hospitals and insurance companies identify patients who should qualify for “high-risk care management” programs, the algorithm assigns each patient a risk score. It predicts a patient’s total medical expenditure based on data from insurance claims (age, sex, diagnosis codes, etc.) and uses this variable as a proxy for health care needs.  Patient risk scores are then generated as functions of their predicted expenditures.\n",
    "\n",
    "If the model is calibrated across race in terms of risk score and expenditure, Black and White patients with a given risk score should have similar total medical expenditures, on average.\n",
    "\n",
    "To see if this is true, we will generate a graph that shows the mean total medical expenditure by race given a risk score percentile.\n",
    "\n",
    "First, let's load our medical data. This data represents the estimated risk across patients, along with other details about each patient. You can [grab the data here](https://github.com/daylight-lab/mlfailures/blob/master/health-care-bias-lab.csv). (If you're using this lab as a Jupyter notebook on your computer, place the file in the same directory as your lab. If you're using Google Colab, Click the Files menu in the sidebar and press the upload file button to upload this CSV.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>risk_score_t</th>\n",
       "      <th>program_enrolled_t</th>\n",
       "      <th>cost_t</th>\n",
       "      <th>cost_avoidable_t</th>\n",
       "      <th>bps_mean_t</th>\n",
       "      <th>ghba1c_mean_t</th>\n",
       "      <th>hct_mean_t</th>\n",
       "      <th>cre_mean_t</th>\n",
       "      <th>ldl_mean_t</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>trig_min-high_tm1</th>\n",
       "      <th>trig_min-normal_tm1</th>\n",
       "      <th>trig_mean-low_tm1</th>\n",
       "      <th>trig_mean-high_tm1</th>\n",
       "      <th>trig_mean-normal_tm1</th>\n",
       "      <th>trig_max-low_tm1</th>\n",
       "      <th>trig_max-high_tm1</th>\n",
       "      <th>trig_max-normal_tm1</th>\n",
       "      <th>gagne_sum_tm1</th>\n",
       "      <th>gagne_sum_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.987430</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>194.0</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.677934</td>\n",
       "      <td>0</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>40.4</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.407678</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798369</td>\n",
       "      <td>0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.513165</td>\n",
       "      <td>0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>1.303333</td>\n",
       "      <td>53.0</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   risk_score_t  program_enrolled_t  cost_t  cost_avoidable_t  bps_mean_t  \\\n",
       "0      1.987430                   0  1200.0               0.0         NaN   \n",
       "1      7.677934                   0  2600.0               0.0       119.0   \n",
       "2      0.407678                   0   500.0               0.0         NaN   \n",
       "3      0.798369                   0  1300.0               0.0       117.0   \n",
       "4     17.513165                   0  1100.0               0.0       116.0   \n",
       "\n",
       "   ghba1c_mean_t  hct_mean_t  cre_mean_t  ldl_mean_t   race  ...  \\\n",
       "0            5.4         NaN    1.110000       194.0  white  ...   \n",
       "1            5.5        40.4    0.860000        93.0  white  ...   \n",
       "2            NaN         NaN         NaN         NaN  white  ...   \n",
       "3            NaN         NaN         NaN         NaN  white  ...   \n",
       "4            NaN        34.1    1.303333        53.0  white  ...   \n",
       "\n",
       "   trig_min-high_tm1  trig_min-normal_tm1  trig_mean-low_tm1  \\\n",
       "0                0.0                  0.0                0.0   \n",
       "1                0.0                  1.0                0.0   \n",
       "2                0.0                  0.0                0.0   \n",
       "3                0.0                  0.0                0.0   \n",
       "4                0.0                  0.0                0.0   \n",
       "\n",
       "   trig_mean-high_tm1  trig_mean-normal_tm1  trig_max-low_tm1  \\\n",
       "0                 0.0                   0.0               0.0   \n",
       "1                 0.0                   1.0               0.0   \n",
       "2                 0.0                   0.0               0.0   \n",
       "3                 0.0                   0.0               0.0   \n",
       "4                 0.0                   0.0               0.0   \n",
       "\n",
       "   trig_max-high_tm1  trig_max-normal_tm1  gagne_sum_tm1  gagne_sum_t  \n",
       "0                0.0                  0.0            0.0          0.0  \n",
       "1                0.0                  1.0            4.0          3.0  \n",
       "2                0.0                  0.0            0.0          0.0  \n",
       "3                0.0                  0.0            0.0          0.0  \n",
       "4                0.0                  0.0            1.0          1.0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('health-care-bias-lab.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "qRr4YHhrJs0X",
    "outputId": "c5a4ea63-50d8-49f5-e6a4-a67419689a96"
   },
   "outputs": [],
   "source": [
    "# TODO: Add a coolumn to the dataframe called \"risk percentile\" with the percentile of the risk score \n",
    "# (`risk_score_t`) for each observation\n",
    "# HINT: Try using pandas qcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r6PlT59kLq_F"
   },
   "outputs": [],
   "source": [
    "# TODO create dataframe called `group_cost` with the mean total medical expenditure (`cost_t`) for each race (`race`) \n",
    "# at each risk percentile (`risk_percentile`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "K2FmeKvoLKMT"
   },
   "outputs": [],
   "source": [
    "# TODO: Divide `group_cost` into two dataframes based on race. Call the two dataframes `b_cost` and `w_cost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hqoKswf-JV7K"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot risk percentile against cost, splitting on race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EHyhQ6HJXbf"
   },
   "source": [
    "**QUESTION: What do you notice about the relationship between medical expenditure and risk score by race? Can you conclude from this data that the model is fair or not fair?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19CQRP0cJvU5"
   },
   "source": [
    "## Chronic illness and risk\n",
    "\n",
    "Next, we will check to see if the model is calibrated across groups in terms of risk score and chronic illness. In other words: for a given risk score, do Black and white patients have the same \"level\" of health? \n",
    "\n",
    "If cost is a good proxy for need, we would expect this graph to be as balanced as the prior graph.  In other words, health care cost should not vary conditional on health between groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "45SnmB-XLTEz"
   },
   "outputs": [],
   "source": [
    "# TODO Group the data by `risk_percentile` and `race`. Take the mean number of chronic illnesses (`gagne_sum_t`) in \n",
    "# each group of race + risk percentile. Call that dataframe `grouped_by_race`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "W62DjFtgsGCM"
   },
   "outputs": [],
   "source": [
    "# TODO Plot risk percentile against average number of chronic ilnesses, splitting on race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIEeHKYUKb-j"
   },
   "source": [
    "**QUESTION: What do you notice about the relationship between chronic illness and risk score by race?  Can you conclude from this data that the model is fair or not fair?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION: How might we test for a statistically significant difference in chronic illnesses by race, conditioned on risk percentile?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit two linear regressions for chronic illness regressed on risk percentile (one for each race). \n",
    "# What do you notice about the coefficients? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZhqmFQOKuxi"
   },
   "source": [
    "## Interactions between cost and illness\n",
    "\n",
    "Our work above shows us that a Black patient and a White patient with the same risk score tend to spend the same amount on medical care on average, yet the Black patient tends to have more chronic illnesses.\n",
    "\n",
    "To understand this interaction, generate a graph that shows the mean total medical expenditure by race, given the number of chronic illnesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OootdJVKLyCx"
   },
   "outputs": [],
   "source": [
    "# TODO: Add a column of illness percentiles to the dataframe called 'illness_percentile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RYBDYKD_uaSq"
   },
   "outputs": [],
   "source": [
    "# TODO: Group the data by `illness_percentile` and `race`. Take the mean total medical expenditure (`cost_t`) for \n",
    "# each group of race + illness percentile. Call the dataframe called `illnesses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO divide illnesses into two dataframes based on race: `illness_b` and `illness_w`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0GE1_aZaMxy_"
   },
   "outputs": [],
   "source": [
    "# TODO create a scatterplot of illness percentile against costs, splitting on race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWVBYMvMNRei"
   },
   "source": [
    "**QUESTION: What can you conclude about the relationship between cost and chronic illness? Why might this relationship exist? What are consequences for the risk score model?**\n",
    "\n",
    "**OPTIONAL**: Fit a LOWESS (locally weighted scatterplot smoothing) model to the scatterplot. Or perhaps there's some other model you'd like to try out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esq4RAPfOnro"
   },
   "source": [
    "## Conclusions and takeaways\n",
    "\n",
    "Even systems that appear balanced across racial groups at first glance may belie underlying biases in the datasets. Thus, seemingly unbiased predictors can in fact be highly correlated with a biasing variable such as race, gender, income or other relational characteristics.\n",
    "\n",
    "In this example, bias emerged from using an indicator of need (cost) that was itself influenced by race. Biased estimation of need between races resulted.\n",
    "\n",
    "To better understand the ways in which race influences health care cost, here is a segment from Obermeyer et al’s paper:\n",
    " \n",
    ">The literature broadly suggests two main potential channels. **First, poor patients face substantial barriers to accessing health care, even when enrolled in insurance plans.** Although the population we study is entirely insured, there are many other mechanisms by which poverty can lead to disparities in use of health care: geography and differential access to transportation, competing demands from jobs or child care, or knowledge of reasons to seek care (1-3). To the extent that race and socioeconomic status are correlated, these factors will differentially affect Black patients. **Second, race could affect costs directly via several channels: direct (“taste-based”) discrimination, changes to the doctor–patient relationship, or others. A recent trial randomly assigned Black patients to a Black or White primary care provider and found significantly higher uptake of recommended preventive care when the provider was Black (4).** This is perhaps the most rigorous demonstration of this effect, and it fits with a larger literature on potential mechanisms by which race can affect health care directly. For example, it has long been documented that Black patients have reduced trust in the health care system (5), a fact that some studies trace to the revelations of the Tuskegee study and other adverse experiences (6). A substantial literature in psychology has documented physicians’ differential perceptions of Black patients, in terms of intelligence, affiliation (7), or pain tolerance (8). **Thus, whether it is communication, trust, or bias, something about the interactions of Black patients with the health care system itself leads to reduced use of health care. The collective effect of these many channels is to lower health spending substantially for Black patients, conditional on need—a finding that has been appreciated for at least two decades (9).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZckgMXS24TYX"
   },
   "source": [
    "## Reflection Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeHiQ6fz3nuC"
   },
   "source": [
    "Here are two final open-ended questions for you to answer.\n",
    "\n",
    "1. How could we use the data we have to create new proxies for health needs that may be less biased than medical costs?\n",
    "\n",
    "\n",
    "2. What are other applications of prediction algorithms where this type of bias may also arise?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpnQ5tGH4A-9"
   },
   "source": [
    "## References\n",
    "\n",
    "1. K. Fiscella, P. Franks, M. R. Gold, C. M. Clancy, JAMA 283, 2579–2584 (2000).\n",
    "2. N. E. Adler, K. Newman, Health Aff. 21, 60–76 (2002).\n",
    "3. N. E. Adler, W. T. Boyce, M. A. Chesney, S. Folkman, S. L. Syme, JAMA 269, 3140–3145 (1993).\n",
    "4. M. Alsan, O. Garrick, G. C. Graziani, “Does diversity matter for health? Experimental evidence from Oakland” (National Bureau of Economic Research, 2018).\n",
    "5. K. Armstrong, K. L. Ravenell, S. McMurphy, M. Putt, Am. J. Public Health 97, 1283–1289 (2007).\n",
    "6. M. Alsan, M. Wanamaker, Q. J. Econ. 133, 407–455 (2018).\n",
    "7. M. van Ryn, J. Burke, Soc. Sci. Med. 50, 813–828 (2000).\n",
    "8. K. M. Hoffman, S. Trawalter, J. R. Axt, M. N. Oliver, Proc. Natl. Acad. Sci. U.S.A. 113, 4296–4301 (2016).\n",
    "9. J. J. Escarce, F. W. Puffer, in Racial and Ethnic Differences in the Health of Older Americans (National Academies Press, 1997), chap. 6; www.ncbi.nlm.nih.gov/books/ NBK109841/.\n",
    "\n",
    "# Feedback\n",
    "\n",
    "**Instructors**: Please [provide feedback](https://docs.google.com/forms/d/1UuUVBBMTU_2aMvzsGnTR_4i1w3F6tLaaqdIr7dQrgSI/edit?ts=5efa771b&dods) to help improve this lab.\n",
    "\n",
    "**Students**: Please [provide feedback](https://docs.google.com/forms/d/1jI8oXRkqD1l1ARuZR1y9W_qkOystPr-YEyywNDez46M/edit?ts=5efa772a&dods) to help improve this lab.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "@mlfailures - Health Care Bias Lab - Applied ML Fairness Mini-Bootcamp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
