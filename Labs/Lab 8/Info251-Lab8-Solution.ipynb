{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8 - Neural Networks\n",
    "- **Author:** Emily Aiken ([emilyaiken@berkeley.edu](mailto:emilyaiken@berkeley.edu))\n",
    "- **Date:** March 16, 2022\n",
    "- **Course:** INFO 251: Applied machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics:\n",
    "1. Neural networks (regression)\n",
    "2. Neural networks (classification)\n",
    "3. Neural networks (multiclass classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals:\n",
    "At the end of this lab, you will...\n",
    "- Know how to code up feed forward neural networks in Keras for regression, classification, and multiclass classification problems\n",
    "- Know the main hyperparameters for neural networks: number of hidden layers, number of hidden nodes, activation functions\n",
    "- Know the main optimization parameters for neural networks: optimizer, learning rate, batch size, epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "- [Keras activation functions](https://keras.io/api/layers/activations/)\n",
    "- [Keras optimizers](https://keras.io/api/optimizers/)\n",
    "- [Keras loss functions](https://keras.io/api/losses/)\n",
    "- [Keras performance metrics](https://keras.io/api/metrics/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Regression Data: Loading and Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "data = datasets.load_boston()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        mean, std = df[col].mean(), df[col].std()\n",
    "        df[col] = (df[col] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test\n",
    "train, test = train_test_split(df, shuffle=True, test_size=0.25, random_state=0)\n",
    "x_train, y_train = train.drop('target', axis=1), train['target']\n",
    "x_test, y_test = test.drop('target', axis=1), test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF r2 on training set: 0.98\n",
      "RF r2 on test set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Let's fit a basic random forest model -- just as a baseline\n",
    "model = RandomForestRegressor(max_depth=8, n_estimators=50, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "print('RF r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('RF r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Neural Network (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Scikit-learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 on training set: 0.77\n",
      "r2 on test set: 0.58\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=[5, 3], activation='relu', solver='adam', max_iter=500,\n",
    "                    shuffle=True, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "# Get metrics\n",
    "print('r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 on training set: 0.65\n",
      "r2 on test set: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Random seeds\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# Define NN\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=len(x_train.columns), activation='relu')) # First layer defines input_dim\n",
    "model.add(Dense(1, activation='linear')) # For regression/classification, last layer of size 1\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse']) # No r2 metric available in keras\n",
    "\n",
    "# Fit and predict with NN\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=10, verbose=0)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "# Get metrics\n",
    "print('r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 on training set: 0.94\n",
      "r2 on test set: 0.81\n"
     ]
    }
   ],
   "source": [
    "# TODO: Tune the hyperparameters until the r2 score on the test set exceeds that of the random forest\n",
    "# Random seeds\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# Define NN\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=len(x_train.columns), activation='relu')) # First layer defines input_dim\n",
    "model.add(Dense(10, activation='relu')) # First layer defines input_dim\n",
    "model.add(Dense(1, activation='linear')) # For regression/classification, last layer of size 1\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse']) # No r2 metric available in keras\n",
    "\n",
    "# Fit and predict with NN\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=5, verbose=0)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "# Get metrics\n",
    "print('r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Classification Data: Loading and Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.887089</td>\n",
       "      <td>11.786745</td>\n",
       "      <td>97.412238</td>\n",
       "      <td>1285.976341</td>\n",
       "      <td>0.168614</td>\n",
       "      <td>0.308313</td>\n",
       "      <td>0.026358</td>\n",
       "      <td>0.190491</td>\n",
       "      <td>0.362086</td>\n",
       "      <td>0.066410</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.906665</td>\n",
       "      <td>362.911363</td>\n",
       "      <td>-49.050592</td>\n",
       "      <td>0.128160</td>\n",
       "      <td>0.010495</td>\n",
       "      <td>0.905038</td>\n",
       "      <td>0.336757</td>\n",
       "      <td>0.323227</td>\n",
       "      <td>0.231988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.946562</td>\n",
       "      <td>9.857078</td>\n",
       "      <td>216.805684</td>\n",
       "      <td>-2603.394391</td>\n",
       "      <td>0.043558</td>\n",
       "      <td>-0.004412</td>\n",
       "      <td>-0.244151</td>\n",
       "      <td>-0.024154</td>\n",
       "      <td>0.148703</td>\n",
       "      <td>0.107751</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.868511</td>\n",
       "      <td>241.870562</td>\n",
       "      <td>-2539.739095</td>\n",
       "      <td>0.158484</td>\n",
       "      <td>1.422741</td>\n",
       "      <td>0.294084</td>\n",
       "      <td>0.091141</td>\n",
       "      <td>-0.038541</td>\n",
       "      <td>0.258604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.244788</td>\n",
       "      <td>32.335553</td>\n",
       "      <td>40.280585</td>\n",
       "      <td>4026.141822</td>\n",
       "      <td>-0.003135</td>\n",
       "      <td>0.378844</td>\n",
       "      <td>0.776733</td>\n",
       "      <td>0.241175</td>\n",
       "      <td>0.231942</td>\n",
       "      <td>0.037065</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.630216</td>\n",
       "      <td>183.694892</td>\n",
       "      <td>2538.407099</td>\n",
       "      <td>0.105701</td>\n",
       "      <td>-0.694013</td>\n",
       "      <td>1.773170</td>\n",
       "      <td>0.197306</td>\n",
       "      <td>0.459990</td>\n",
       "      <td>0.116640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.704775</td>\n",
       "      <td>26.774269</td>\n",
       "      <td>64.925556</td>\n",
       "      <td>1023.365281</td>\n",
       "      <td>0.135199</td>\n",
       "      <td>0.529861</td>\n",
       "      <td>0.844492</td>\n",
       "      <td>-0.032502</td>\n",
       "      <td>0.254744</td>\n",
       "      <td>0.104587</td>\n",
       "      <td>...</td>\n",
       "      <td>34.714214</td>\n",
       "      <td>118.254599</td>\n",
       "      <td>-4205.038762</td>\n",
       "      <td>0.381332</td>\n",
       "      <td>-0.571568</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.489827</td>\n",
       "      <td>0.648660</td>\n",
       "      <td>0.222814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.488955</td>\n",
       "      <td>46.219440</td>\n",
       "      <td>184.189166</td>\n",
       "      <td>3483.886208</td>\n",
       "      <td>0.089133</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.292348</td>\n",
       "      <td>0.116302</td>\n",
       "      <td>0.162262</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>...</td>\n",
       "      <td>37.406781</td>\n",
       "      <td>120.237160</td>\n",
       "      <td>1042.451770</td>\n",
       "      <td>0.135641</td>\n",
       "      <td>0.051512</td>\n",
       "      <td>1.082255</td>\n",
       "      <td>-0.444460</td>\n",
       "      <td>-0.125717</td>\n",
       "      <td>0.132616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter    mean area  mean smoothness  \\\n",
       "0    40.887089     11.786745       97.412238  1285.976341         0.168614   \n",
       "1    11.946562      9.857078      216.805684 -2603.394391         0.043558   \n",
       "2    12.244788     32.335553       40.280585  4026.141822        -0.003135   \n",
       "3    -3.704775     26.774269       64.925556  1023.365281         0.135199   \n",
       "4    32.488955     46.219440      184.189166  3483.886208         0.089133   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.308313        0.026358             0.190491       0.362086   \n",
       "1         -0.004412       -0.244151            -0.024154       0.148703   \n",
       "2          0.378844        0.776733             0.241175       0.231942   \n",
       "3          0.529861        0.844492            -0.032502       0.254744   \n",
       "4          0.032960        0.292348             0.116302       0.162262   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter   worst area  \\\n",
       "0                0.066410  ...     -13.906665       362.911363   -49.050592   \n",
       "1                0.107751  ...     -10.868511       241.870562 -2539.739095   \n",
       "2                0.037065  ...     -36.630216       183.694892  2538.407099   \n",
       "3                0.104587  ...      34.714214       118.254599 -4205.038762   \n",
       "4               -0.000282  ...      37.406781       120.237160  1042.451770   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          0.128160           0.010495         0.905038              0.336757   \n",
       "1          0.158484           1.422741         0.294084              0.091141   \n",
       "2          0.105701          -0.694013         1.773170              0.197306   \n",
       "3          0.381332          -0.571568         0.001554              0.489827   \n",
       "4          0.135641           0.051512         1.082255             -0.444460   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0        0.323227                 0.231988       0  \n",
       "1       -0.038541                 0.258604       0  \n",
       "2        0.459990                 0.116640       0  \n",
       "3        0.648660                 0.222814       0  \n",
       "4       -0.125717                 0.132616       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        df[col] = df[col] + np.random.normal(0, 4*df[col].std(), len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        mean, std = df[col].mean(), df[col].std()\n",
    "        df[col] = (df[col] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test\n",
    "train, test = train_test_split(df, shuffle=True, test_size=0.25, random_state=0)\n",
    "x_train, y_train = train.drop('target', axis=1), train['target']\n",
    "x_test, y_test = test.drop('target', axis=1), test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF AUC on training set: 0.97\n",
      "RF AUC on test set: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Let's fit a basic random forest model -- just as a baseline\n",
    "model = RandomForestClassifier(max_depth=4, n_estimators=50, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_train = model.predict_proba(x_train)[:, 1]\n",
    "yhat_test = model.predict_proba(x_test)[:, 1]\n",
    "print('RF AUC on training set: %.2f' % roc_auc_score(y_train, yhat_train))\n",
    "print('RF AUC on test set: %.2f' % roc_auc_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Neural Network (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-424ba2e2518e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Train a neural network to predict malignance. Tune hyperparameters until the AUC score exceeds that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# of the random forest above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Train a neural network to predict malignance. Tune hyperparameters until the AUC score exceeds that\n",
    "# of the random forest above.\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# Define NN\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=len(x_train.columns), activation='relu')) # First layer defines input_dim\n",
    "model.add(Dense(1, activation='sigmoid')) # For regression/classification, last layer of size 1\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC']) # No r2 metric available in keras\n",
    "\n",
    "# Fit and predict with NN\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=10, verbose=1)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "# Get metrics\n",
    "print('AUC on training set: %.2f' % roc_auc_score(y_train, yhat_train))\n",
    "print('AUC on test set: %.2f' % roc_auc_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Multiclass Classification Data Loading and Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.504747</td>\n",
       "      <td>4.748949</td>\n",
       "      <td>2.601480</td>\n",
       "      <td>11.739500</td>\n",
       "      <td>125.182287</td>\n",
       "      <td>3.797853</td>\n",
       "      <td>2.098297</td>\n",
       "      <td>-0.351655</td>\n",
       "      <td>1.003620</td>\n",
       "      <td>-0.830891</td>\n",
       "      <td>2.718510</td>\n",
       "      <td>4.241905</td>\n",
       "      <td>3847.096222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.213440</td>\n",
       "      <td>0.350940</td>\n",
       "      <td>1.931256</td>\n",
       "      <td>5.966019</td>\n",
       "      <td>106.426417</td>\n",
       "      <td>2.169337</td>\n",
       "      <td>-0.658779</td>\n",
       "      <td>1.135534</td>\n",
       "      <td>2.014843</td>\n",
       "      <td>-0.982897</td>\n",
       "      <td>1.221235</td>\n",
       "      <td>2.477744</td>\n",
       "      <td>641.461948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.444865</td>\n",
       "      <td>-3.326536</td>\n",
       "      <td>2.177566</td>\n",
       "      <td>27.737064</td>\n",
       "      <td>117.457887</td>\n",
       "      <td>-4.844807</td>\n",
       "      <td>-4.943451</td>\n",
       "      <td>0.186871</td>\n",
       "      <td>7.773352</td>\n",
       "      <td>-2.178549</td>\n",
       "      <td>1.797575</td>\n",
       "      <td>2.110637</td>\n",
       "      <td>2185.058480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.885742</td>\n",
       "      <td>3.351114</td>\n",
       "      <td>1.762072</td>\n",
       "      <td>12.079059</td>\n",
       "      <td>198.586822</td>\n",
       "      <td>5.051264</td>\n",
       "      <td>5.423326</td>\n",
       "      <td>-0.122147</td>\n",
       "      <td>3.892414</td>\n",
       "      <td>15.078533</td>\n",
       "      <td>0.260579</td>\n",
       "      <td>-0.333696</td>\n",
       "      <td>2245.056564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.050244</td>\n",
       "      <td>4.838524</td>\n",
       "      <td>2.258219</td>\n",
       "      <td>-2.883396</td>\n",
       "      <td>100.805252</td>\n",
       "      <td>-1.087033</td>\n",
       "      <td>8.917637</td>\n",
       "      <td>-0.119661</td>\n",
       "      <td>2.446909</td>\n",
       "      <td>19.465605</td>\n",
       "      <td>1.209760</td>\n",
       "      <td>-2.851885</td>\n",
       "      <td>-630.388596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid       ash  alcalinity_of_ash   magnesium  \\\n",
       "0  19.504747    4.748949  2.601480          11.739500  125.182287   \n",
       "1  11.213440    0.350940  1.931256           5.966019  106.426417   \n",
       "2  11.444865   -3.326536  2.177566          27.737064  117.457887   \n",
       "3  10.885742    3.351114  1.762072          12.079059  198.586822   \n",
       "4  16.050244    4.838524  2.258219          -2.883396  100.805252   \n",
       "\n",
       "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0       3.797853    2.098297             -0.351655         1.003620   \n",
       "1       2.169337   -0.658779              1.135534         2.014843   \n",
       "2      -4.844807   -4.943451              0.186871         7.773352   \n",
       "3       5.051264    5.423326             -0.122147         3.892414   \n",
       "4      -1.087033    8.917637             -0.119661         2.446909   \n",
       "\n",
       "   color_intensity       hue  od280/od315_of_diluted_wines      proline  \\\n",
       "0        -0.830891  2.718510                      4.241905  3847.096222   \n",
       "1        -0.982897  1.221235                      2.477744   641.461948   \n",
       "2        -2.178549  1.797575                      2.110637  2185.058480   \n",
       "3        15.078533  0.260579                     -0.333696  2245.056564   \n",
       "4        19.465605  1.209760                     -2.851885  -630.388596   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        df[col] = df[col] + np.random.normal(0, 4*df[col].std(), len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        mean, std = df[col].mean(), df[col].std()\n",
    "        df[col] = (df[col] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test\n",
    "train, test = train_test_split(df, shuffle=True, test_size=0.25, random_state=0)\n",
    "x_train, y_train = train.drop('target', axis=1), train['target']\n",
    "x_test, y_test = test.drop('target', axis=1), test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy on training set: 1.00\n",
      "RF accuracy on test set: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Let's fit a basic random forest model -- just as a baseline\n",
    "model = RandomForestClassifier(max_depth=6, n_estimators=50, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "print('RF accuracy on training set: %.2f' % accuracy_score(y_train, yhat_train))\n",
    "print('RF accuracy on test set: %.2f' % accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Neural Network (Multiclass Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.53\n",
      "Accuracy on test set: 0.44\n"
     ]
    }
   ],
   "source": [
    "# Random seeds\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# One hot encode the y variable\n",
    "y_train_dummies = pd.get_dummies(y_train)\n",
    "y_test_dummies = pd.get_dummies(y_test)\n",
    "\n",
    "# Define NN\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=len(x_train.columns), activation='relu')) # First layer defines input_dim\n",
    "model.add(Dense(len(y_train_dummies.columns), activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# Fit and predict with NN\n",
    "model.fit(x_train, y_train_dummies, epochs=50, batch_size=10, verbose=0)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "# Convert probabilities to categorical predictions\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "# Get metrics\n",
    "print('Accuracy on training set: %.2f' % accuracy_score(y_train, yhat_train))\n",
    "print('Accuracy on test set: %.2f' % accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.83\n",
      "Accuracy on test set: 0.33\n"
     ]
    }
   ],
   "source": [
    "# TODO: Tune the hyperparameters until the overall accuracy score exceeds that of the random forest\n",
    "# Random seeds\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# One hot encode the y variable\n",
    "y_train_dummies = pd.get_dummies(y_train)\n",
    "y_test_dummies = pd.get_dummies(y_test)\n",
    "\n",
    "# Define NN\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=len(x_train.columns), activation='relu')) # First layer defines input_dim\n",
    "model.add(Dense(20, activation='relu')) # First layer defines input_dim\n",
    "model.add(Dense(len(y_train_dummies.columns), activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# Fit and predict with NN\n",
    "model.fit(x_train, y_train_dummies, epochs=20, batch_size=2, verbose=0)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "# Convert probabilities to categorical predictions\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "# Get metrics\n",
    "print('Accuracy on training set: %.2f' % accuracy_score(y_train, yhat_train))\n",
    "print('Accuracy on test set: %.2f' % accuracy_score(y_test, yhat_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
