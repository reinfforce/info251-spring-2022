{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8 - Neural Networks\n",
    "- **Author:** Emily Aiken ([emilyaiken@berkeley.edu](mailto:emilyaiken@berkeley.edu))\n",
    "- **Date:** March 16, 2022\n",
    "- **Course:** INFO 251: Applied machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics:\n",
    "1. Neural networks (regression)\n",
    "2. Neural networks (classification)\n",
    "3. Neural networks (multiclass classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals:\n",
    "At the end of this lab, you will...\n",
    "- Know how to code up feed forward neural networks in Keras for regression, classification, and multiclass classification problems\n",
    "- Know the main hyperparameters for neural networks: number of hidden layers, number of hidden nodes, activation functions\n",
    "- Know the main optimization parameters for neural networks: optimizer, learning rate, batch size, epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "- [Keras activation functions](https://keras.io/api/layers/activations/)\n",
    "- [Keras optimizers](https://keras.io/api/optimizers/)\n",
    "- [Keras loss functions](https://keras.io/api/losses/)\n",
    "- [Keras performance metrics](https://keras.io/api/metrics/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, roc_auc_score, accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Regression Data: Loading and Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "data = datasets.load_boston()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        mean, std = df[col].mean(), df[col].std()\n",
    "        df[col] = (df[col] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test\n",
    "train, test = train_test_split(df, shuffle=True, test_size=0.25, random_state=0)\n",
    "x_train, y_train = train.drop('target', axis=1), train['target']\n",
    "x_test, y_test = test.drop('target', axis=1), test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF r2 on training set: 0.98\n",
      "RF r2 on test set: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Let's fit a basic random forest model -- just as a baseline\n",
    "model = RandomForestRegressor(max_depth=8, n_estimators=50, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "print('RF r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('RF r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Neural Network (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Scikit-learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 on training set: 0.77\n",
      "r2 on test set: 0.58\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=[5, 3], activation='relu', solver='adam', max_iter=500,\n",
    "                    shuffle=True, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "# Get metrics\n",
    "print('r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 on training set: 0.65\n",
      "r2 on test set: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Random seeds\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# Define NN\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=len(x_train.columns), activation='relu')) # First layer defines input_dim\n",
    "model.add(Dense(1, activation='linear')) # For regression/classification, last layer of size 1\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse']) # No r2 metric available in keras\n",
    "\n",
    "# Fit and predict with NN\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=10, verbose=0)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "# Get metrics\n",
    "print('r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune the hyperparameters until the r2 score on the test set exceeds that of the random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Classification Data: Loading and Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.215214</td>\n",
       "      <td>29.609666</td>\n",
       "      <td>237.235447</td>\n",
       "      <td>957.253337</td>\n",
       "      <td>0.075135</td>\n",
       "      <td>0.159193</td>\n",
       "      <td>0.479545</td>\n",
       "      <td>-0.071647</td>\n",
       "      <td>0.285759</td>\n",
       "      <td>0.025896</td>\n",
       "      <td>...</td>\n",
       "      <td>55.990891</td>\n",
       "      <td>93.878385</td>\n",
       "      <td>-922.594251</td>\n",
       "      <td>0.222788</td>\n",
       "      <td>1.144124</td>\n",
       "      <td>0.275914</td>\n",
       "      <td>0.259383</td>\n",
       "      <td>0.401851</td>\n",
       "      <td>0.093737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.852780</td>\n",
       "      <td>10.468181</td>\n",
       "      <td>233.091104</td>\n",
       "      <td>2997.133173</td>\n",
       "      <td>0.202155</td>\n",
       "      <td>0.337712</td>\n",
       "      <td>-0.272807</td>\n",
       "      <td>0.232042</td>\n",
       "      <td>0.032971</td>\n",
       "      <td>0.073385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.941621</td>\n",
       "      <td>-21.039659</td>\n",
       "      <td>1830.481937</td>\n",
       "      <td>0.071908</td>\n",
       "      <td>0.145836</td>\n",
       "      <td>1.144626</td>\n",
       "      <td>0.297835</td>\n",
       "      <td>0.229907</td>\n",
       "      <td>0.201592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.038096</td>\n",
       "      <td>-0.372287</td>\n",
       "      <td>97.239263</td>\n",
       "      <td>2599.881859</td>\n",
       "      <td>0.103950</td>\n",
       "      <td>0.471920</td>\n",
       "      <td>0.848899</td>\n",
       "      <td>0.111572</td>\n",
       "      <td>0.334732</td>\n",
       "      <td>0.084134</td>\n",
       "      <td>...</td>\n",
       "      <td>28.195078</td>\n",
       "      <td>114.552176</td>\n",
       "      <td>1137.989482</td>\n",
       "      <td>0.203666</td>\n",
       "      <td>-0.184891</td>\n",
       "      <td>1.374075</td>\n",
       "      <td>0.680334</td>\n",
       "      <td>0.400192</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.344638</td>\n",
       "      <td>28.715720</td>\n",
       "      <td>-84.247511</td>\n",
       "      <td>1149.990156</td>\n",
       "      <td>0.134138</td>\n",
       "      <td>0.155378</td>\n",
       "      <td>-0.060954</td>\n",
       "      <td>-0.076007</td>\n",
       "      <td>0.202641</td>\n",
       "      <td>0.102352</td>\n",
       "      <td>...</td>\n",
       "      <td>23.208891</td>\n",
       "      <td>52.822893</td>\n",
       "      <td>2918.450449</td>\n",
       "      <td>0.175880</td>\n",
       "      <td>-0.059224</td>\n",
       "      <td>1.138680</td>\n",
       "      <td>0.296743</td>\n",
       "      <td>0.747734</td>\n",
       "      <td>0.177588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.649647</td>\n",
       "      <td>31.003179</td>\n",
       "      <td>3.117436</td>\n",
       "      <td>3042.472837</td>\n",
       "      <td>-0.014671</td>\n",
       "      <td>0.287769</td>\n",
       "      <td>0.630249</td>\n",
       "      <td>-0.005492</td>\n",
       "      <td>0.034629</td>\n",
       "      <td>0.066990</td>\n",
       "      <td>...</td>\n",
       "      <td>37.821356</td>\n",
       "      <td>116.864101</td>\n",
       "      <td>4639.176265</td>\n",
       "      <td>0.350309</td>\n",
       "      <td>1.459490</td>\n",
       "      <td>0.520597</td>\n",
       "      <td>-0.288537</td>\n",
       "      <td>0.392953</td>\n",
       "      <td>0.115381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter    mean area  mean smoothness  \\\n",
       "0    -6.215214     29.609666      237.235447   957.253337         0.075135   \n",
       "1    30.852780     10.468181      233.091104  2997.133173         0.202155   \n",
       "2    14.038096     -0.372287       97.239263  2599.881859         0.103950   \n",
       "3    -9.344638     28.715720      -84.247511  1149.990156         0.134138   \n",
       "4    26.649647     31.003179        3.117436  3042.472837        -0.014671   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.159193        0.479545            -0.071647       0.285759   \n",
       "1          0.337712       -0.272807             0.232042       0.032971   \n",
       "2          0.471920        0.848899             0.111572       0.334732   \n",
       "3          0.155378       -0.060954            -0.076007       0.202641   \n",
       "4          0.287769        0.630249            -0.005492       0.034629   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter   worst area  \\\n",
       "0                0.025896  ...      55.990891        93.878385  -922.594251   \n",
       "1                0.073385  ...       1.941621       -21.039659  1830.481937   \n",
       "2                0.084134  ...      28.195078       114.552176  1137.989482   \n",
       "3                0.102352  ...      23.208891        52.822893  2918.450449   \n",
       "4                0.066990  ...      37.821356       116.864101  4639.176265   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          0.222788           1.144124         0.275914              0.259383   \n",
       "1          0.071908           0.145836         1.144626              0.297835   \n",
       "2          0.203666          -0.184891         1.374075              0.680334   \n",
       "3          0.175880          -0.059224         1.138680              0.296743   \n",
       "4          0.350309           1.459490         0.520597             -0.288537   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0        0.401851                 0.093737       0  \n",
       "1        0.229907                 0.201592       0  \n",
       "2        0.400192                 0.022262       0  \n",
       "3        0.747734                 0.177588       0  \n",
       "4        0.392953                 0.115381       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = datasets.load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        df[col] = df[col] + np.random.normal(0, 4*df[col].std(), len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        mean, std = df[col].mean(), df[col].std()\n",
    "        df[col] = (df[col] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test\n",
    "train, test = train_test_split(df, shuffle=True, test_size=0.25, random_state=0)\n",
    "x_train, y_train = train.drop('target', axis=1), train['target']\n",
    "x_test, y_test = test.drop('target', axis=1), test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF AUC on training set: 0.98\n",
      "RF AUC on test set: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Let's fit a basic random forest model -- just as a baseline\n",
    "model = RandomForestClassifier(max_depth=4, n_estimators=50, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_train = model.predict_proba(x_train)[:, 1]\n",
    "yhat_test = model.predict_proba(x_test)[:, 1]\n",
    "print('RF AUC on training set: %.2f' % roc_auc_score(y_train, yhat_train))\n",
    "print('RF AUC on test set: %.2f' % roc_auc_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Neural Network (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a neural network to predict malignance. Tune hyperparameters until the AUC score exceeds that\n",
    "# of the random forest above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Multiclass Classification Data Loading and Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = datasets.load_wine()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        df[col] = df[col] + np.random.normal(0, 4*df[col].std(), len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "for col in df.columns:\n",
    "    if col != 'target':\n",
    "        mean, std = df[col].mean(), df[col].std()\n",
    "        df[col] = (df[col] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test\n",
    "train, test = train_test_split(df, shuffle=True, test_size=0.25, random_state=0)\n",
    "x_train, y_train = train.drop('target', axis=1), train['target']\n",
    "x_test, y_test = test.drop('target', axis=1), test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit a basic random forest model -- just as a baseline\n",
    "model = RandomForestClassifier(max_depth=6, n_estimators=50, random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "print('RF accuracy on training set: %.2f' % accuracy_score(y_train, yhat_train))\n",
    "print('RF accuracy on test set: %.2f' % accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Neural Network (Multiclass Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# One hot encode the y variable\n",
    "y_train_dummies = pd.get_dummies(y_train)\n",
    "y_test_dummies = pd.get_dummies(y_test)\n",
    "\n",
    "# Define NN\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=len(x_train.columns), activation='relu')) # First layer defines input_dim\n",
    "model.add(Dense(len(y_train_dummies.columns), activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# Fit and predict with NN\n",
    "model.fit(x_train, y_train_dummies, epochs=50, batch_size=10, verbose=0)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "# Convert probabilities to categorical predictions\n",
    "yhat_train = np.argmax(yhat_train, axis=1)\n",
    "yhat_test = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "# Get metrics\n",
    "print('Accuracy on training set: %.2f' % accuracy_score(y_train, yhat_train))\n",
    "print('Accuracy on test set: %.2f' % accuracy_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune the hyperparameters until the overall accuracy score exceeds that of the random forest\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
